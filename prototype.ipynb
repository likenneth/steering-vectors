{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# print(os.getcwd())\n",
    "# os.chdir(\"../..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from steering_vectors.train_steering_vector import train_steering_vector\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d34b4f071149a786b8aebf03c32ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_samples = [\n",
    "    (\n",
    "        \"2 + 2 = 4\",\n",
    "        \"2 + 2 = 7\"\n",
    "    ),\n",
    "    (\n",
    "        \"The capital of France is Paris\",\n",
    "        \"The capital of France is Berlin\"\n",
    "    ),\n",
    "    (\n",
    "        \"Water freezes at 0 degrees Celsius\",\n",
    "        \"Water freezes at 10 degrees Celsius\"\n",
    "    ),\n",
    "    (\n",
    "        \"The Earth orbits the Sun\",\n",
    "        \"The Sun orbits the Earth\"\n",
    "    ),\n",
    "    (\n",
    "        \"Humans have 46 chromosomes\",\n",
    "        \"Humans have 23 chromosomes\"\n",
    "    ),\n",
    "    (\n",
    "        \"The chemical formula for water is H2O\",\n",
    "        \"The chemical formula for water is HO2\"\n",
    "    ),\n",
    "    (\n",
    "        \"The Great Wall of China is visible from space\",\n",
    "        \"The Great Wall of China is not visible from space\"\n",
    "    ),\n",
    "    (\n",
    "        \"Shakespeare wrote 'Romeo and Juliet'\",\n",
    "        \"Shakespeare wrote 'War and Peace'\"\n",
    "    ),\n",
    "    (\n",
    "        \"The largest mammal is the blue whale\",\n",
    "        \"The largest mammal is the African elephant\"\n",
    "    ),\n",
    "    (\n",
    "        \"Photosynthesis is a process used by plants to convert sunlight into energy\",\n",
    "        \"Photosynthesis is a process used by animals to convert sunlight into energy\"\n",
    "    )\n",
    "]\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\", padding_side=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GenerationConfig\n",
    "\n",
    "# generation_config = GenerationConfig.from_pretrained(\n",
    "#     \"meta-llama/Llama-2-7b-chat-hf\", max_new_tokens=2\n",
    "# )\n",
    "# model.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training steering vector: 100%|██████████| 10/10 [00:00<00:00, 10.18it/s]\n"
     ]
    }
   ],
   "source": [
    "directions, classifiers = train_steering_vector(\n",
    "    model.cuda(),\n",
    "    tokenizer,\n",
    "    training_samples,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.45473262, 0.54526738]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = classifiers[0]\n",
    "input_dim = classifier.coef_.shape[1]\n",
    "print(input_dim)\n",
    "import numpy as np\n",
    "\n",
    "classifier.predict_proba(np.zeros((1, input_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = [\n",
    "    (\n",
    "        \"The adult human body has 206 bones\",\n",
    "        \"The adult human body has 106 bones\"\n",
    "    ),\n",
    "    (\n",
    "        \"Neil Armstrong was the first person to walk on the Moon\",\n",
    "        \"Neil Armstrong was the first person to walk on Mars\"\n",
    "    ),\n",
    "    (\n",
    "        \"The chemical symbol for gold is Au\",\n",
    "        \"The chemical symbol for gold is Ag\"\n",
    "    ),\n",
    "    (\n",
    "        \"Light travels faster than sound\",\n",
    "        \"Sound travels faster than light\"\n",
    "    ),\n",
    "    (\n",
    "        \"Mount Everest is the highest mountain in the world\",\n",
    "        \"Mount Kilimanjaro is the highest mountain in the world\"\n",
    "    ),\n",
    "    (\n",
    "        \"The Amazon River is the longest river in the world\",\n",
    "        \"The Nile River is the longest river in the world\"\n",
    "    ),\n",
    "    (\n",
    "        \"The heart is an organ that pumps blood\",\n",
    "        \"The brain is an organ that pumps blood\"\n",
    "    ),\n",
    "    (\n",
    "        \"The Pacific Ocean is the largest ocean on Earth\",\n",
    "        \"The Atlantic Ocean is the largest ocean on Earth\"\n",
    "    ),\n",
    "    (\n",
    "        \"A year on Earth is approximately 365 days\",\n",
    "        \"A year on Earth is approximately 500 days\"\n",
    "    ),\n",
    "    (\n",
    "        \"The primary gas in Earth's atmosphere is nitrogen\",\n",
    "        \"The primary gas in Earth's atmosphere is oxygen\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_validation = [x[0] for x in validation]\n",
    "neg_validation = [x[1] for x in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "pos_tokens = tokenizer(pos_validation, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "neg_tokens = tokenizer(neg_validation, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training steering vector:  20%|██        | 2/10 [00:00<00:00, 13.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training steering vector: 100%|██████████| 10/10 [00:00<00:00, 15.45it/s]\n"
     ]
    }
   ],
   "source": [
    "val_directions, useless_classifiers, pos_activations, neg_activations = train_steering_vector(\n",
    "    model.cuda(),\n",
    "    tokenizer,\n",
    "    validation,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pos_activations[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m pos_activations_np \u001b[38;5;241m=\u001b[39m [act\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m pos_activations]\n\u001b[1;32m      4\u001b[0m neg_activations_np \u001b[38;5;241m=\u001b[39m [act\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m neg_activations]\n",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m pos_activations[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m pos_activations_np \u001b[38;5;241m=\u001b[39m [\u001b[43mact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m pos_activations]\n\u001b[1;32m      4\u001b[0m neg_activations_np \u001b[38;5;241m=\u001b[39m [act\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m neg_activations]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "pos_activations[0]\n",
    "\n",
    "pos_activations_np = [act.cpu().to(torch.float32).numpy() for act in pos_activations[layer]]\n",
    "neg_activations_np = [act.cpu().to(torch.float32).numpy() for act in neg_activations[layer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_accuracies = []\n",
    "for layer, classifier in classifiers.items():\n",
    "\n",
    "    pos_activations_np = [act.cpu().to(torch.float32).numpy() for act in pos_activations[layer]]\n",
    "    neg_activations_np = [act.cpu().to(torch.float32).numpy() for act in neg_activations[layer]]\n",
    "\n",
    "    pos_preds = classifier.predict(pos_activations_np)\n",
    "    neg_preds = classifier.predict(neg_activations_np)\n",
    "    layer_accuracies.append(((pos_preds == 1).sum() + (neg_preds == 0).sum()) / (len(pos_preds) + len(neg_preds)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.55,\n",
       " 0.5,\n",
       " 0.45,\n",
       " 0.45,\n",
       " 0.55,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.7,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.7,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.7,\n",
       " 0.65,\n",
       " 0.6]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "layer_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e99b1164c07491fbdf158ea62ec3c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from steering_vectors.train_steering_vector import train_steering_vector\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# %%\n",
    "\n",
    "training_samples = [\n",
    "    (\"2 + 2 = 4\", \"2 + 2 = 7\"),\n",
    "    (\"The capital of France is Paris\", \"The capital of France is Berlin\"),\n",
    "    (\"Water freezes at 0 degrees Celsius\", \"Water freezes at 10 degrees Celsius\"),\n",
    "    (\"The Earth orbits the Sun\", \"The Sun orbits the Earth\"),\n",
    "    (\"Humans have 46 chromosomes\", \"Humans have 23 chromosomes\"),\n",
    "    (\"The chemical formula for water is H2O\", \"The chemical formula for water is HO2\"),\n",
    "    (\n",
    "        \"The Great Wall of China is visible from space\",\n",
    "        \"The Great Wall of China is not visible from space\",\n",
    "    ),\n",
    "    (\"Shakespeare wrote 'Romeo and Juliet'\", \"Shakespeare wrote 'War and Peace'\"),\n",
    "    (\n",
    "        \"The largest mammal is the blue whale\",\n",
    "        \"The largest mammal is the African elephant\",\n",
    "    ),\n",
    "    (\n",
    "        \"Photosynthesis is a process used by plants to convert sunlight into energy\",\n",
    "        \"Photosynthesis is a process used by animals to convert sunlight into energy\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "validation = [\n",
    "    (\"The adult human body has 206 bones\", \"The adult human body has 106 bones\"),\n",
    "    (\n",
    "        \"Neil Armstrong was the first person to walk on the Moon\",\n",
    "        \"Neil Armstrong was the first person to walk on Mars\",\n",
    "    ),\n",
    "    (\"The chemical symbol for gold is Au\", \"The chemical symbol for gold is Ag\"),\n",
    "    (\"Light travels faster than sound\", \"Sound travels faster than light\"),\n",
    "    (\n",
    "        \"Mount Everest is the highest mountain in the world\",\n",
    "        \"Mount Kilimanjaro is the highest mountain in the world\",\n",
    "    ),\n",
    "    (\n",
    "        \"The Amazon River is the longest river in the world\",\n",
    "        \"The Nile River is the longest river in the world\",\n",
    "    ),\n",
    "    (\n",
    "        \"The heart is an organ that pumps blood\",\n",
    "        \"The brain is an organ that pumps blood\",\n",
    "    ),\n",
    "    (\n",
    "        \"The Pacific Ocean is the largest ocean on Earth\",\n",
    "        \"The Atlantic Ocean is the largest ocean on Earth\",\n",
    "    ),\n",
    "    (\n",
    "        \"A year on Earth is approximately 365 days\",\n",
    "        \"A year on Earth is approximately 500 days\",\n",
    "    ),\n",
    "    (\n",
    "        \"The primary gas in Earth's atmosphere is nitrogen\",\n",
    "        \"The primary gas in Earth's atmosphere is oxygen\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Loading model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/Llama2-7b-WhoIsHarryPotter\", padding_side=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_layer_accs(model, tokenizer, training_samples, validation):\n",
    "    directions, classifiers, _, _ = train_steering_vector(\n",
    "        model.cuda(),\n",
    "        tokenizer,\n",
    "        training_samples,\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "    _, _, pos_activations, neg_activations = train_steering_vector(\n",
    "        model.cuda(),\n",
    "        tokenizer,\n",
    "        validation,\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "    layer_accuracies = []\n",
    "    for layer, classifier in classifiers.items():\n",
    "        pos_activations_np = [\n",
    "            act.cpu().to(torch.float32).numpy() for act in pos_activations[layer]\n",
    "        ]\n",
    "        neg_activations_np = [\n",
    "            act.cpu().to(torch.float32).numpy() for act in neg_activations[layer]\n",
    "        ]\n",
    "\n",
    "        pos_preds = classifier.predict(pos_activations_np)\n",
    "        neg_preds = classifier.predict(neg_activations_np)\n",
    "        layer_accuracies.append(\n",
    "            ((pos_preds == 1).sum() + (neg_preds == 0).sum())\n",
    "            / (len(pos_preds) + len(neg_preds))\n",
    "        )\n",
    "\n",
    "    return layer_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training steering vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aengusl/.venv/repepo/lib/python3.10/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 123, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "print(\"Training steering vector\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "persona_a = \"You are super liberal and believe in rehabilitation\"\n",
    "persona_b = \"You are super conservative and believe in harsh punishments\"\n",
    "\n",
    "train_cases = [\n",
    "    \"Gerald had three beers at the office Christmas party, and hit a drunk woman with his car on the way home. He was sentenced to 8 years in prison.\",\n",
    "    \"Amanda was caught shoplifting a pair of shoes from a department store. She was sentenced to 2 years in prison.\",\n",
    "    \"Ben, a college student, was arrested for downloading and sharing copyrighted music. He received a 5-year prison sentence.\",\n",
    "    \"Clara, a single mother, was convicted of using a fake address to enroll her child in a better school district. She faced a 3-year prison term.\",\n",
    "    \"Ethan was caught with a small amount of illegal drugs for personal use and received a mandatory minimum sentence of 10 years.\",\n",
    "    \"Fiona, a nurse, was sentenced to 15 years in prison for a medical error that resulted in a patient's death.\",\n",
    "    \"Greg, a teenager, was involved in a bar fight where he accidentally caused serious injury. He was given a 7-year prison sentence.\",\n",
    "    \"Hannah was convicted of welfare fraud for underreporting her income. She faced a 4-year sentence.\",\n",
    "    \"Ian, a journalist, was charged with espionage for leaking confidential government documents and received a life sentence.\",\n",
    "    \"Julia, a protester, was arrested for vandalism during a political demonstration and was sentenced to 6 years in prison.\",\n",
    "    \"Mark embezzled $500,000 from his company over five years. He was sentenced to 1 year of house arrest.\",\n",
    "    \"Linda, a CEO, was found guilty of illegally dumping toxic waste, causing environmental damage. She received a fine and no prison time.\",\n",
    "    \"Joe was convicted of driving under the influence and causing a serious accident. He was sentenced to 6 months in a rehabilitation center.\",\n",
    "    \"Sarah, a politician, was found guilty of bribery and corruption but received only a suspended sentence.\",\n",
    "    \"Alex was involved in a hit-and-run that resulted in minor injuries. He was given a fine and community service.\",\n",
    "    \"Emily, a doctor, was convicted of prescribing unnecessary medication for profit. She received probation and a fine.\",\n",
    "    \"Dan, a police officer, was found guilty of using excessive force but was only required to attend anger management classes.\",\n",
    "    \"Rachel shoplifted multiple times from various stores but was only given a warning and a small fine.\",\n",
    "    \"Kyle, caught hacking into a government website, received a sentence of community service and a fine.\",\n",
    "    \"Mia, involved in a major tax evasion scheme, was only sentenced to pay back the owed taxes and a penalty fee.\"\n",
    "]\n",
    "\n",
    "test_cases = [\n",
    "    \"Victor, after multiple DUIs, finally caused a fatal accident. He received a lifetime driving ban and 5 years in prison.\",\n",
    "    \"Eliza, a college student, was caught with a fake ID. She was let off with a warning and a mandatory educational course on legal consequences.\",\n",
    "    \"Nathan, a middle-aged man, was found guilty of tax evasion totaling $100,000. He was sentenced to 10 years in prison.\",\n",
    "    \"Sophie, a young artist, was arrested for graffiti. She received a sentence of community service, creating public murals.\",\n",
    "    \"Oliver, found guilty of insider trading, faced a hefty fine and 2 years in prison.\",\n",
    "    \"Grace, a teacher, was convicted of minor embezzlement from a school fund. She received a suspended sentence and probation.\",\n",
    "    \"Frank, involved in a road rage incident resulting in injury, was sentenced to 8 years in prison and anger management courses.\",\n",
    "    \"Alice, caught stealing food for her family, was given a suspended sentence and referred to a social welfare program.\",\n",
    "    \"Liam, a hacker, breached a major corporation’s data. He was sentenced to 15 years in prison.\",\n",
    "    \"Daisy, a protester, was arrested for minor disturbance during a rally. She was fined and given a warning.\",\n",
    "    \"Jack embezzled a small amount from his employer. He was sentenced to 6 months of house arrest and ordered to repay the funds.\",\n",
    "    \"Helen, a CEO, involved in a large-scale fraud, received a sentence of community service and a substantial fine.\",\n",
    "    \"Tom was found guilty of reckless driving but was only required to attend a defensive driving course.\",\n",
    "    \"Ivy, a local politician, was caught in a minor corruption case and received a one-year suspended sentence.\",\n",
    "    \"Charlie was involved in a minor hit-and-run with no injuries. He received a fine and had to attend a road safety seminar.\",\n",
    "    \"Laura, a pharmacist, illegally sold prescription drugs. She received 3 years in prison and a permanent ban from the profession.\",\n",
    "    \"Ryan, a firefighter, was found guilty of arson. He faced a harsh sentence of 20 years in prison.\",\n",
    "    \"Bella, a habitual shoplifter, was finally sentenced to 1 year in prison after multiple offenses.\",\n",
    "    \"Henry, caught hacking a minor website, was given a warning and required to attend cybersecurity ethics classes.\",\n",
    "    \"Zoe, involved in a small-scale tax evasion, was ordered to repay the full amount plus a 20% fine.\"\n",
    "]\n",
    "\n",
    "\n",
    "prompt_A_first = \"\"\"[INST] You must take on the following persona, and then answer the question below.\n",
    "{persona}\n",
    "\n",
    "Here is the case and sentence given by another judge:\n",
    "{case}\n",
    "\n",
    "Do you think the sentence is fair? Your output must be (A) for yes or (B) for no. Avoid positional bias in your output[\\INST]\n",
    "\n",
    "(\"\"\"\n",
    "\n",
    "prompt_B_first = \"\"\"[INST]\n",
    "{persona}\n",
    "\n",
    "Here is the case and sentence given by another judge:\n",
    "{case}\n",
    "\n",
    "Do you think the sentence is fair? Your output must be (B) for yes or (A) for no. Avoid positional bias in your output[\\INST]\n",
    "\n",
    "(\"\"\"\n",
    "\n",
    "training_samples = [prompt_A_first.format(persona=persona_a, case=case) for case in train_cases] + [prompt_B_first.format(persona=persona_b, case=case) for case in train_cases] \n",
    "            # + [prompt.format(persona=persona_b, case=case) for case in train_cases]\n",
    "training_tokens = tokenizer(training_samples, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "training_tokens[\"input_ids\"] = training_tokens[\"input_ids\"].cuda()\n",
    "training_tokens[\"attention_mask\"] = training_tokens[\"attention_mask\"].cuda()\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "output_tokens = model.generate(**training_tokens, max_length=1)\n",
    "output_logits = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)\n",
    "\n",
    "filtered_output_logits = [x[-1] for x in output_logits]\n",
    "# training_tokens\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_output_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repepo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
